import os
import mlflow
from sklearn.metrics import accuracy_score
import streamlit as st
import tensorflow as tf
import numpy as np
import cv2
from streamlit_drawable_canvas import st_canvas
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.datasets import mnist
from sklearn.model_selection import train_test_split
def log_experiment(model_name):
    try:
        st.warning('M√¥ h√¨nh ƒëang ƒë∆∞·ª£c Log')
        DAGSHUB_USERNAME = "toancodepython"  # Thay b·∫±ng username c·ªßa b·∫°n
        DAGSHUB_REPO_NAME = "ml-flow"
        DAGSHUB_TOKEN = "a6e8c1682e60df503248dcf37f42ca15ceaee13a"  # Thay b·∫±ng Access Token c·ªßa b·∫°n
        mlflow.set_tracking_uri("https://dagshub.com/toancodepython/ml-flow.mlflow")
        # Thi·∫øt l·∫≠p authentication b·∫±ng Access Token
        os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
        os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

        experiment_name = "Neural Network"
        experiment = next((exp for exp in mlflow.search_experiments() if exp.name == experiment_name), None)
        if experiment:
            experiment_id = experiment.experiment_id
            print(f"Experiment ID: {experiment_id}")
            mlflow.set_experiment(experiment_name)
            with mlflow.start_run(run_name = model_name) as run:
                print('Logging...')
                mlflow.log_param("num_neurons", st.session_state.number)
                mlflow.log_param("num_hidden_layers", st.session_state.hidden_layer)
                mlflow.log_param("epochs", st.session_state.epoch)
                mlflow.log_param("optimizer", st.session_state.optimizer)
                mlflow.log_param("Learning rate", st.session_state.learning_rate)
                mlflow.log_param("Activation", st.session_state.activation)

                mlflow.log_metric("Test Accuracy", st.session_state.accuracy)
                mlflow.log_metric("Validation Accuracy", st.session_state.accuracy_val)

                mlflow.keras.log_model(st.session_state.model, "model")
                mlflow.register_model(f"runs:/{run.info.run_id}/model", model_name)
                st.success(f"‚úÖ M√¥ h√¨nh ƒë∆∞·ª£c log v√†o th√≠ nghi·ªám: {experiment_name}")
        else:
            # N·∫øu th√≠ nghi·ªám ch∆∞a t·ªìn t·∫°i, t·∫°o m·ªõi
            experiment_id = mlflow.create_experiment(experiment_name)
        print("Active Run:", mlflow.active_run())
    except Exception as e:
        st.warning("Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi MLflow ho·∫∑c DagsHub. Vui l√≤ng ki·ªÉm tra c√†i ƒë·∫∑t.")
# X√¢y d·ª±ng m√¥ h√¨nh
def create_model(num_hidden_layers, num_neurons,optimizer):
    model = Sequential([Flatten(input_shape=(28, 28))])
    for _ in range(num_hidden_layers):
        model.add(Dense(num_neurons, activation='relu'))
    model.add(Dense(10, activation='softmax'))
    model.compile(optimizer=optimizer, loss=st.session_state.loss, metrics=['accuracy'])
    return model

def display():
    # Load MNIST dataset
    (x, y), (_, _) = mnist.load_data()
    x = x / 255.0  # Chu·∫©n h√≥a d·ªØ li·ªáu

    # Streamlit UI
    st.title("üìä Classification on MNIST with Neural Network")
    st.header("üìÇ Data Selection")
    # L·ª±a ch·ªçn s·ªë l∆∞·ª£ng m·∫´u d·ªØ li·ªáu
    st.write("**S·ªë l∆∞·ª£ng m·∫´u**: S·ªë l∆∞·ª£ng ·∫£nh ƒë∆∞·ª£c s·ª≠ d·ª•ng cho vi·ªác hu·∫•n luy·ªán v√† ki·ªÉm tra.")
    num_samples = int(st.number_input("S·ªë l∆∞·ª£ng m·∫´u", 1000, 70000, 70000, step=1000, key='neu_1'))

    st.write("**T·ªâ l·ªá t·∫≠p hu·∫•n luy·ªán**: Ph·∫ßn trƒÉm d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.")
    train_ratio = float(st.number_input("T·ªâ l·ªá t·∫≠p hu·∫•n luy·ªán", 0.5, 0.9, 0.8, step=0.05, key='neu_2'))

    st.write("**T·ªâ l·ªá t·∫≠p validation**: Ph·∫ßn trƒÉm d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh trong qu√° tr√¨nh hu·∫•n luy·ªán.")
    val_ratio = float(st.number_input("T·ªâ l·ªá t·∫≠p validation", 0.05, 0.3, 0.1, step=0.05, key='neu_3'))
    test_ratio = 1 - train_ratio
    # Chia t·∫≠p d·ªØ li·ªáu
    x_train, x_test, y_train, y_test = train_test_split(x[:num_samples], y[:num_samples], test_size= test_ratio, random_state=42)  # 20% test
    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=val_ratio, random_state=42)  # 25% c·ªßa train th√†nh val (~20% t·ªïng)

    st.write(f"S·ªë l∆∞·ª£ng m·∫´u hu·∫•n luy·ªán: {len(x_train)}, m·∫´u validation: {len(x_val)}, m·∫´u ki·ªÉm tra: {len(x_test)}")
    st.header("‚öôÔ∏è Neural Network Parameters")
    # Tham s·ªë m√¥ h√¨nh
    st.write("**S·ªë neuron m·ªói l·ªõp**: S·ªë l∆∞·ª£ng neuron trong m·ªói l·ªõp ·∫©n c·ªßa m√¥ h√¨nh.")
    num_neurons = int(st.number_input("S·ªë neuron m·ªói l·ªõp", 32, 512, 128, step=32, key='neu_6'))
    st.session_state.number = num_neurons
    st.write("**S·ªë l·ªõp ·∫©n**: S·ªë l∆∞·ª£ng l·ªõp k·∫øt n·ªëi trong m·∫°ng neuron.")
    num_hidden_layers = int(st.number_input("S·ªë l·ªõp ·∫©n", 1, 5, 2, key='neu_7'))
    st.session_state.hidden_layer = num_hidden_layers
    st.write("**S·ªë epochs**: S·ªë l·∫ßn m√¥ h√¨nh duy·ªát qua to√†n b·ªô t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán.")
    epochs = int(st.number_input("S·ªë epochs", 5, 50, 10, step=5, key='neu_8'))
    st.session_state.epoch = epochs
    st.write("**Optimizer**: Thu·∫≠t to√°n t·ªëi ∆∞u h√≥a gi√∫p gi·∫£m thi·ªÉu h√†m m·∫•t m√°t.")
    optimizer = st.selectbox("Optimizer", ["adam", "sgd", "rmsprop"])
    st.session_state.optimizer = optimizer
    activation = st.selectbox("Activation", ["relu", "softmax"], key='semi_12')
    st.session_state.activation = activation
    learning_rate = st.number_input("T·ªëc ƒë·ªô h·ªçc", min_value=0.01, max_value=1.0, value=0.01, key='neu_9')
    st.session_state.learning_rate = learning_rate
    st.session_state.loss = 'sparse_categorical_crossentropy'
    if "accuracy" not in st.session_state:
        st.session_state.accuracy = 0
    if "accuracy_val" not in st.session_state:
        st.session_state.accuracy_val = 0
    if "number" not in st.session_state:
        st.session_state.number = 0
    if "train_sample" not in st.session_state:
        st.session_state.train_sample = 0
    if "test_sample" not in st.session_state:
        st.session_state.test_sample = 0
    if "val_sample" not in st.session_state:
        st.session_state.val_sample = 0
    if "hidden_layer" not in st.session_state:
        st.session_state.hidden_layer = 0
    if "epoch" not in st.session_state:
        st.session_state.epoch = 0
    if "optimizer" not in st.session_state:
        st.session_state.optimizer = 0
    if "loss" not in st.session_state:
        st.session_state.loss = 0
    if "log_success" not in st.session_state:
        st.session_state.log_success = False
    if "model" not in st.session_state:
        st.session_state.model = None
    # Hu·∫•n luy·ªán m√¥ h√¨nh
    run_name = st.text_input("üè∑Ô∏è Nh·∫≠p t√™n Run", key = "neural_10")

    if st.button("‚ñ∂Ô∏è Hu·∫•n luy·ªán m√¥ h√¨nh", key='neu_btn_1'):
        model = create_model(num_hidden_layers=num_hidden_layers, num_neurons=num_neurons, optimizer=optimizer)
        with st.spinner("ƒêang hu·∫•n luy·ªán..."):
            model.fit(x_train, y_train, epochs=epochs, batch_size=5, verbose=0)
            st.session_state.model = model
            y_pred_classes = model.predict(x_test).argmax(axis=1)  # Chuy·ªÉn ƒë·ªïi nh√£n d·ª± ƒëo√°n
            y_pred_val_classes = model.predict(x_val).argmax(axis=1)  # Chuy·ªÉn ƒë·ªïi nh√£n d·ª± ƒëo√°n
            st.session_state.accuracy = accuracy_score(y_test, y_pred_classes) 
            st.session_state.accuracy_val = accuracy_score(y_pred_val_classes, y_val)  # L∆∞u ƒë·ªô ch√≠nh x√°c
             # L∆∞u ƒë·ªô ch√≠nh x√°c
        st.success("Hu·∫•n luy·ªán th√†nh c√¥ng!")
        st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p Test: {st.session_state.accuracy:.4f}")
        st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p Validation: {st.session_state.accuracy_val:.4f}")
        st.session_state.model = model
        log_experiment(run_name)
    if st.session_state.model is not None:
        model_dict = get_logged_models('Neural Network')
        selected_model_name = st.selectbox("Ch·ªçn m√¥ h√¨nh ƒë·ªÉ d·ª± ƒëo√°n:", list(model_dict.keys()))
        st.subheader("Draw a digit and predict")

        canvas_result = st_canvas(
            fill_color="black",  # M√†u n·ªÅn
            stroke_width=10,
            stroke_color="black",
            background_color="white",
            height=250,
            width=250,
            drawing_mode="freedraw",
            key='neural_'
        )
        if st.button("Predict Drawn Digit", key= 'neu_btn_2'):
            if canvas_result.image_data is not None:
                print('start predict')
                try: 
                    run_id = model_dict[selected_model_name]
                    model_uri = f"runs:/{run_id}/model"
                    model_loaded = mlflow.keras.load_model(model_uri)
                    if(model_loaded): st.success('Model loaded')
                    img = cv2.cvtColor(canvas_result.image_data.astype(np.uint8), cv2.COLOR_RGBA2GRAY)
                    img = cv2.resize(img, (28, 28))
                    img = img / 255.0
                    img = np.expand_dims(img, axis=0)
                    prediction = model_loaded.predict(img)
                    st.write(prediction)
                    predicted_digit = np.argmax(prediction)
                    confidence = np.max(prediction)
                    st.write(f"Predicted Digit: {predicted_digit}, Confidence: {confidence:.2f}")
                except Exception as e:
                    st.warning(e)
            else:
                st.warning("‚ö†Ô∏è Vui l√≤ng v·∫Ω m·ªôt s·ªë tr∆∞·ªõc khi d·ª± ƒëo√°n!")
def get_logged_models(experiment_name):
    try:

        DAGSHUB_USERNAME = "toancodepython"
        DAGSHUB_REPO_NAME = "ml-flow"
        DAGSHUB_TOKEN = "a6e8c1682e60df503248dcf37f42ca15ceaee13a"
        mlflow.set_tracking_uri("https://dagshub.com/toancodepython/ml-flow.mlflow")
        os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
        os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

        experiment = next((exp for exp in mlflow.search_experiments() if exp.name == experiment_name), None)
        if experiment:
            runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])
            return {row["tags.mlflow.runName"]: row["run_id"] for _, row in runs.iterrows()}
        return {}
    except Exception as e:
        st.warning("Kh√¥ng th·ªÉ l·∫•y danh s√°ch m√¥ h√¨nh t·ª´ MLflow.")
        
        return []

def neural():
    tab1, tab3 = st.tabs(["‚öôÔ∏è Hu·∫•n luy·ªán", "üî•Mlflow"])

    with tab1:
        display()
    with tab3:
        import mlflow_web
        mlflow_web.display()

neural()