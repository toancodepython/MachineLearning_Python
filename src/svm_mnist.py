import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
import pickle
import mlflow
import os
from tensorflow.keras.datasets import mnist
from streamlit_drawable_canvas import st_canvas
import cv2
def load_data():
    train_data = pd.read_csv("data/mnist/train.csv")
    X = train_data.iloc[:, 1:].values / 255.0
    y = train_data.iloc[:, 0].values
    return train_data, X, y
def log_experiment(model_name):
    try:
        DAGSHUB_USERNAME = "toancodepython"  # Thay b·∫±ng username c·ªßa b·∫°n
        DAGSHUB_REPO_NAME = "ml-flow"
        DAGSHUB_TOKEN = "a6e8c1682e60df503248dcf37f42ca15ceaee13a"  # Thay b·∫±ng Access Token c·ªßa b·∫°n
        mlflow.set_tracking_uri("https://dagshub.com/toancodepython/ml-flow.mlflow")
        # Thi·∫øt l·∫≠p authentication b·∫±ng Access Token
        os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
        os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN
        experiment_name = "SVM_Classification"
        experiment = next((exp for exp in mlflow.search_experiments() if exp.name == experiment_name), None)
        if experiment:
            experiment_id = experiment.experiment_id
            print(f"Experiment ID: {experiment_id}")
            mlflow.set_experiment(experiment_name)
            with mlflow.start_run(run_name = model_name) as run:
                print('Logging...')
                mlflow.log_param("C", st.session_state.c)
                mlflow.log_param("Kernel", st.session_state.kernel)
                
                mlflow.log_metric("Test Accuracy", st.session_state.accuracy)
                mlflow.log_metric("Validation Accuracy", st.session_state.accuracy_val)

                st.success(f"‚úÖ M√¥ h√¨nh ƒë∆∞·ª£c log v√†o th√≠ nghi·ªám: {experiment_name}")
        else:
            # N·∫øu th√≠ nghi·ªám ch∆∞a t·ªìn t·∫°i, t·∫°o m·ªõi
            experiment_id = mlflow.create_experiment(experiment_name)
        print("Active Run:", mlflow.active_run())
    except Exception as e:
        st.warning("Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi MLflow ho·∫∑c DagsHub. Vui l√≤ng ki·ªÉm tra c√†i ƒë·∫∑t.")
def show_sample_images():
    train_data = pd.read_csv("data/mnist/train.csv")
    unique_labels = train_data.iloc[:, 0].unique()
    fig, axes = plt.subplots(2, 5, figsize=(10, 5))
    label_count = 0
    
    for i, ax in enumerate(axes.flat):
        if label_count >= len(unique_labels):
            break
        sample = train_data[train_data.iloc[:, 0] == unique_labels[label_count]].iloc[0, 1:].values.reshape(28, 28)
        ax.imshow(sample, cmap='gray')
        ax.set_title(f"Label: {unique_labels[label_count]}", fontsize=10)
        ax.axis("off")
        label_count += 1
    st.pyplot(fig)

def plot_label_distribution(y):
    fig, ax = plt.subplots(figsize=(8, 5))
    pd.Series(y).value_counts().sort_index().plot(kind="bar", ax=ax, color="skyblue")
    ax.set_title("Label Distribution in Dataset")
    ax.set_xlabel("Digit Label")
    ax.set_ylabel("Count")
    st.pyplot(fig)

def display():
    st.title("Nh·∫≠n di·ªán ch·ªØ s·ªë MNIST b·∫±ng SVM")
    st.header("Tham s·ªë m√¥ h√¨nh")
    (x, y), (_, _) = mnist.load_data()
    x = x / 255.0  # Chu·∫©n h√≥a d·ªØ li·ªáu
    x = x.reshape(x.shape[0], -1)
    # L·ª±a ch·ªçn s·ªë l∆∞·ª£ng m·∫´u d·ªØ li·ªáu
    st.write("**S·ªë l∆∞·ª£ng m·∫´u**: S·ªë l∆∞·ª£ng ·∫£nh ƒë∆∞·ª£c s·ª≠ d·ª•ng cho vi·ªác hu·∫•n luy·ªán v√† ki·ªÉm tra.")
    num_samples = int(st.number_input("S·ªë l∆∞·ª£ng m·∫´u", 1000, 70000, 70000, step=1000))

    st.write("**T·ªâ l·ªá t·∫≠p hu·∫•n luy·ªán**: Ph·∫ßn trƒÉm d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.")
    train_ratio = float(st.number_input("T·ªâ l·ªá t·∫≠p hu·∫•n luy·ªán", 0.5, 0.9, 0.8, step=0.05))

    st.write("**T·ªâ l·ªá t·∫≠p validation**: Ph·∫ßn trƒÉm d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh trong qu√° tr√¨nh hu·∫•n luy·ªán.")
    val_ratio = float(st.number_input("T·ªâ l·ªá t·∫≠p validation", 0.05, 0.3, 0.1, step=0.05))
    test_ratio = 1 - train_ratio - val_ratio

    # Chia t·∫≠p d·ªØ li·ªáu
    x_train, x_temp, y_train, y_temp = train_test_split(x[:num_samples], y[:num_samples], train_size=train_ratio, stratify=y[:num_samples])
    x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=test_ratio/(test_ratio + val_ratio), stratify=y_temp)

    st.write(f"S·ªë l∆∞·ª£ng m·∫´u hu·∫•n luy·ªán: {len(x_train)}, m·∫´u validation: {len(x_val)}, m·∫´u ki·ªÉm tra: {len(x_test)}")


    if "accuracy" not in st.session_state:
        st.session_state.accuracy = 0
    if "log_success" not in st.session_state:
        st.session_state.log_success = False
    if "accuracy_val" not in st.session_state:
        st.session_state.accuracy_val = 0

    # Choose SVM parameters
    st.write("- **Kernel**: Defines the type of hyperplane used to separate data (linear, polynomial, RBF, or sigmoid).")
    kernel = st.selectbox("Kernel type", ["linear", "poly", "rbf", "sigmoid"])
    st.session_state.kernel = kernel

    st.write("- **C (Regularization parameter)**: Controls the trade-off between achieving a low error and maintaining a simple decision boundary.")
    C = st.slider("C (Regularization parameter)", min_value=0.01, max_value=10.0, value=1.0, step=0.01)
    st.session_state.c = C


    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
        with st.spinner("ƒêang hu·∫•n luy·ªán..."):
            model = SVC(kernel=kernel, C=C, gamma='auto', probability=True)
            model.fit(x_train, y_train)
            st.session_state.model = model
            y_pred_classes = model.predict(x_test) 
            st.session_state.accuracy = accuracy_score(y_test, y_pred_classes) 

            y_pred_val_classes = model.predict(x_val) 
            st.session_state.accuracy_val = accuracy_score(y_val, y_pred_val_classes) 
        st.success("Hu·∫•n luy·ªán th√†nh c√¥ng!")
    st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p Test: {st.session_state.accuracy:.4f}")
    st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p Valdation: {st.session_state.accuracy_val:.4f}")

    st.subheader("V·∫Ω m·ªôt ch·ªØ s·ªë (0-9)")
    canvas = st_canvas(
        fill_color="black",
        stroke_width=10,
        stroke_color="white",
        background_color="black",
        height=200,
        width=200,
        drawing_mode="freedraw",
        key="canvas",
    )
    # D·ª± ƒëo√°n ch·ªØ s·ªë
    if 'model' in st.session_state:
        if canvas.image_data is not None and st.button("D·ª± ƒëo√°n"):
            image = cv2.cvtColor(canvas.image_data.astype(np.uint8), cv2.COLOR_RGBA2GRAY)
            image = cv2.resize(image, (28, 28))
            image = image / 255.0
            image = image.reshape(1, -1)  # Chuy·ªÉn th√†nh vector 1D (1, 784)
            pred_proba = st.session_state.model.predict_proba(image)
            predicted_digit = np.argmax(pred_proba)
            confidence = np.max(pred_proba)
            
            st.write(f"Ch·ªØ s·ªë d·ª± ƒëo√°n: {predicted_digit}")
            st.write(f"ƒê·ªô tin c·∫≠y: {confidence:.4f}")


        model_name = st.text_input("üè∑Ô∏è Nh·∫≠p t√™n m√¥ h√¨nh", key = "0")
        if st.button("Log SVM Model", key = "btn_svm1"):
            log_experiment(model_name) 

        # Hi·ªÉn th·ªã tr·∫°ng th√°i log th√†nh c√¥ng
        if st.session_state.log_success:
            st.success("üöÄ Experiment ƒë√£ ƒë∆∞·ª£c log th√†nh c√¥ng!  Chuy·ªÉn qua tab ML_Flow ƒë·ªÉ xem k·∫øt qu·∫£")