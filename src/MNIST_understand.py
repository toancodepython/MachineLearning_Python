from tensorflow.keras.datasets import mnist
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
def show_sample_images():
    train_data = pd.read_csv("data/mnist/train.csv")
    unique_labels = train_data.iloc[:, 0].unique()
    fig, axes = plt.subplots(2, 5, figsize=(10, 5))
    label_count = 0
    
    for i, ax in enumerate(axes.flat):
        if label_count >= len(unique_labels):
            break
        sample = train_data[train_data.iloc[:, 0] == unique_labels[label_count]].iloc[0, 1:].values.reshape(28, 28)
        ax.imshow(sample, cmap='gray')
        ax.set_title(f"Label: {unique_labels[label_count]}", fontsize=10)
        ax.axis("off")
        label_count += 1
    st.pyplot(fig)

def plot_label_distribution(y):
    fig, ax = plt.subplots(figsize=(8, 5))
    pd.Series(y).value_counts().sort_index().plot(kind="bar", ax=ax, color="skyblue")
    ax.set_title("Label Distribution in Dataset")
    ax.set_xlabel("Digit Label")
    ax.set_ylabel("Count")
    st.pyplot(fig)

def display():
    (x, y), (_, _) = mnist.load_data()
    x = x / 255.0  # Chuáº©n hÃ³a dá»¯ liá»‡u

    st.title("ğŸ–¼ï¸ MNIST Classification using SVM")
    st.header("ğŸ“Œ Step 1: Understanding Data")
    st.write("Below are some sample images from the dataset:")

    show_sample_images()

    st.write("ğŸ”¹ The pixel values are normalized by dividing by 255 to scale them between 0 and 1, which helps improve model performance and convergence speed.")
    x = x.reshape(x.shape[0], -1)
    st.write(f"ğŸ“ Dataset Shape: {x.shape}")


    st.write("ğŸ“Š Label Distribution:")
    plot_label_distribution(y)