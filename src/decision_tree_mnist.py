import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
import pickle
import mlflow
import os
from tensorflow.keras.datasets import mnist
from streamlit_drawable_canvas import st_canvas
from sklearn.tree import DecisionTreeClassifier
import cv2
def load_data():
    train_data = pd.read_csv("data/mnist/train.csv")
    X = train_data.iloc[:, 1:].values / 255.0
    y = train_data.iloc[:, 0].values
    return train_data, X, y
def log_experiment(model_name):
    try:
        st.warning('Model ƒëang ƒë∆∞·ª£c log...')
        DAGSHUB_USERNAME = "toancodepython"  # Thay b·∫±ng username c·ªßa b·∫°n
        DAGSHUB_REPO_NAME = "ml-flow"
        DAGSHUB_TOKEN = "a6e8c1682e60df503248dcf37f42ca15ceaee13a"  # Thay b·∫±ng Access Token c·ªßa b·∫°n
        mlflow.set_tracking_uri("https://dagshub.com/toancodepython/ml-flow.mlflow")
        # Thi·∫øt l·∫≠p authentication b·∫±ng Access Token
        os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
        os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN
        experiment_name = "Decision_Tree_Classification"
        experiment = next((exp for exp in mlflow.search_experiments() if exp.name == experiment_name), None)
        if experiment:
            experiment_id = experiment.experiment_id
            print(f"Experiment ID: {experiment_id}")
            mlflow.set_experiment(experiment_name)
            with mlflow.start_run(run_name = model_name) as run:
                print('Logging...')
                mlflow.log_param("max_depth", st.session_state.max_depth)
                mlflow.log_param("min_samples_split", st.session_state.min_samples_split)
                mlflow.log_param("min_samples_leaf", st.session_state.min_samples_leaf)
                mlflow.log_param("criterion", st.session_state.criterion)

                mlflow.log_metric("Test Accuracy", st.session_state.accuracy)
                mlflow.log_metric("Validation Accuracy", st.session_state.accuracy_val)

                mlflow.sklearn.log_model(st.session_state.model, "model")
                mlflow.register_model(f"runs:/{run.info.run_id}/model", model_name)
                st.success(f"‚úÖ M√¥ h√¨nh ƒë∆∞·ª£c log v√†o th√≠ nghi·ªám: {experiment_name}")
        else:
            # N·∫øu th√≠ nghi·ªám ch∆∞a t·ªìn t·∫°i, t·∫°o m·ªõi
            experiment_id = mlflow.create_experiment(experiment_name)
        print("Active Run:", mlflow.active_run())
    except Exception as e:
        st.warning("Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi MLflow ho·∫∑c DagsHub. Vui l√≤ng ki·ªÉm tra c√†i ƒë·∫∑t.")
def show_sample_images():
    train_data = pd.read_csv("data/mnist/train.csv")
    unique_labels = train_data.iloc[:, 0].unique()
    fig, axes = plt.subplots(2, 5, figsize=(10, 5))
    label_count = 0
    
    for i, ax in enumerate(axes.flat):
        if label_count >= len(unique_labels):
            break
        sample = train_data[train_data.iloc[:, 0] == unique_labels[label_count]].iloc[0, 1:].values.reshape(28, 28)
        ax.imshow(sample, cmap='gray')
        ax.set_title(f"Label: {unique_labels[label_count]}", fontsize=10)
        ax.axis("off")
        label_count += 1
    st.pyplot(fig)

def plot_label_distribution(y):
    fig, ax = plt.subplots(figsize=(8, 5))
    pd.Series(y).value_counts().sort_index().plot(kind="bar", ax=ax, color="skyblue")
    ax.set_title("Label Distribution in Dataset")
    ax.set_xlabel("Digit Label")
    ax.set_ylabel("Count")
    st.pyplot(fig)

def display():
    st.title("üìä Classificaton on MNIST with Decision Tree")

    (x, y), (_, _) = mnist.load_data()
    x = x / 255.0  # Chu·∫©n h√≥a d·ªØ li·ªáu
    x = x.reshape(x.shape[0], -1)
    # L·ª±a ch·ªçn s·ªë l∆∞·ª£ng m·∫´u d·ªØ li·ªáu
    st.header("üìÇ Data Selection")
    st.write("**S·ªë l∆∞·ª£ng m·∫´u**: S·ªë l∆∞·ª£ng ·∫£nh ƒë∆∞·ª£c s·ª≠ d·ª•ng cho vi·ªác hu·∫•n luy·ªán v√† ki·ªÉm tra.")
    num_samples = int(st.number_input("S·ªë l∆∞·ª£ng m·∫´u", 1000, 70000, 70000, step=1000, key = 'tree_1'))

    st.write("**T·ªâ l·ªá t·∫≠p hu·∫•n luy·ªán**: Ph·∫ßn trƒÉm d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.")
    train_ratio = float(st.number_input("T·ªâ l·ªá t·∫≠p hu·∫•n luy·ªán", 0.5, 0.9, 0.8, step=0.05, key = 'tree_2'))

    st.write("**T·ªâ l·ªá t·∫≠p validation**: Ph·∫ßn trƒÉm d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh trong qu√° tr√¨nh hu·∫•n luy·ªán.")
    val_ratio = float(st.number_input("T·ªâ l·ªá t·∫≠p validation", 0.05, 0.3, 0.1, step=0.05, key = 'tree_3'))
    test_ratio = 1 - train_ratio - val_ratio

    # Chia t·∫≠p d·ªØ li·ªáu
    x_train, x_temp, y_train, y_temp = train_test_split(x[:num_samples], y[:num_samples], train_size=train_ratio, stratify=y[:num_samples])
    x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=test_ratio/(test_ratio + val_ratio), stratify=y_temp)

    st.write(f"S·ªë l∆∞·ª£ng m·∫´u hu·∫•n luy·ªán: {len(x_train)}, m·∫´u validation: {len(x_val)}, m·∫´u ki·ªÉm tra: {len(x_test)}")


    if "accuracy" not in st.session_state:
        st.session_state.accuracy = 0
    if "log_success" not in st.session_state:
        st.session_state.log_success = False
    if "accuracy_val" not in st.session_state:
        st.session_state.accuracy_val = 0
    if "model" not in st.session_state:
        st.session_state.model = None
    # Choose SVM parameters
    st.header("‚öôÔ∏è Decision Tree Parameters")
    st.write("- **ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa c√¢y (max_depth)**: Gi·ªõi h·∫°n s·ªë t·∫ßng c·ªßa c√¢y quy·∫øt ƒë·ªãnh. Gi√° tr·ªã cao c√≥ th·ªÉ g√¢y overfitting.")
    max_depth = st.slider("Ch·ªçn ƒë·ªô s√¢u t·ªëi ƒëa c·ªßa c√¢y", 1, 50, 10)
    st.session_state.max_depth = max_depth

    st.write("- **S·ªë m·∫´u t·ªëi thi·ªÉu ƒë·ªÉ chia nh√°nh (min_samples_split)**: S·ªë l∆∞·ª£ng m·∫´u t·ªëi thi·ªÉu c·∫ßn c√≥ ƒë·ªÉ m·ªôt n√∫t ƒë∆∞·ª£c chia th√†nh hai nh√°nh.")
    min_samples_split = st.slider("Ch·ªçn s·ªë m·∫´u t·ªëi thi·ªÉu ƒë·ªÉ chia nh√°nh", 2, 50, 2)
    st.session_state.min_samples_split = min_samples_split

    st.write("- **S·ªë m·∫´u t·ªëi thi·ªÉu ·ªü m·ªôt l√° (min_samples_leaf)**: S·ªë l∆∞·ª£ng m·∫´u t·ªëi thi·ªÉu c·∫ßn c√≥ ·ªü m·ªôt n√∫t l√°.")
    min_samples_leaf = st.slider("Ch·ªçn s·ªë m·∫´u t·ªëi thi·ªÉu ·ªü m·ªôt l√°", 1, 50, 1)
    st.session_state.min_samples_leaf = min_samples_leaf

    st.write("- **H√†m loss (criterion)**: C√°ch t√≠nh ƒë·ªô tinh khi·∫øt c·ªßa n√∫t, c√≥ th·ªÉ ch·ªçn 'gini' (ch·ªâ s·ªë Gini) ho·∫∑c 'entropy' (th√¥ng tin entropy).")
    criterion = st.selectbox("Ch·ªçn h√†m loss", ["gini", "entropy"])
    st.session_state.criterion = criterion
    model_name = st.text_input("üè∑Ô∏è Nh·∫≠p t√™n m√¥ h√¨nh", key = "key = 'tree_1'")
    if st.button("‚ñ∂Ô∏è Hu·∫•n luy·ªán m√¥ h√¨nh", key='tree_btn_2'):
        with st.spinner("ƒêang hu·∫•n luy·ªán..."):
            model = DecisionTreeClassifier(
                max_depth=max_depth,
                min_samples_split=min_samples_split,
                min_samples_leaf=min_samples_leaf,
                criterion=criterion,
            )
            model.fit(x_train, y_train)
            st.session_state.model = model
            y_pred_classes = model.predict(x_test) 
            st.session_state.accuracy = accuracy_score(y_test, y_pred_classes) 
            y_pred_val_classes = model.predict(x_val) 
            st.session_state.accuracy_val = accuracy_score(y_val, y_pred_val_classes) 
        log_experiment(model_name) 
    st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p Test: {st.session_state.accuracy:.4f}")
    st.write(f"ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p Test: {st.session_state.accuracy_val:.4f}")

    if st.session_state.model:
        model_dict = get_logged_models('Decision_Tree_Classification')
        selected_model_name = st.selectbox("Ch·ªçn m√¥ h√¨nh ƒë·ªÉ d·ª± ƒëo√°n:", list(model_dict.keys()))
        st.subheader("Draw a digit and predict")

        canvas_result = st_canvas(
            fill_color="black",  # M√†u n·ªÅn
            stroke_width=10,
            stroke_color="black",
            background_color="white",
            height=250,
            width=250,
            drawing_mode="freedraw",
            key='tree_canva'
        )
        if st.button("Predict Drawn Digit", key='tree_btn_1'):
            if canvas_result.image_data is not None:
                print('start predict')
                try: 
                    run_id = model_dict[selected_model_name]
                    model_uri = f"runs:/{run_id}/model"
                    model_loaded = mlflow.sklearn.load_model(model_uri)
                    if(model_loaded): st.success('Model loaded')
                    img = cv2.cvtColor(canvas_result.image_data.astype(np.uint8), cv2.COLOR_RGBA2GRAY)
                    img = cv2.resize(img, (28, 28))
                    img = img.reshape(1, -1)  # Chuy·ªÉn th√†nh vector 1D (1, 784)
                    img = img / 255.0
                    img = np.expand_dims(img, axis=0)
                    prediction = model_loaded.predict_proba(img)
                    st.write(prediction)
                    predicted_digit = np.argmax(prediction)
                    confidence = np.max(prediction)
                    st.write(f"Predicted Digit: {predicted_digit}, Confidence: {confidence:.2f}")
                except Exception as e:
                    st.warning(e)
            else:
                st.warning("‚ö†Ô∏è Vui l√≤ng v·∫Ω m·ªôt s·ªë tr∆∞·ªõc khi d·ª± ƒëo√°n!")
def get_logged_models(experiment_name):
    try:

        DAGSHUB_USERNAME = "toancodepython"
        DAGSHUB_REPO_NAME = "ml-flow"
        DAGSHUB_TOKEN = "a6e8c1682e60df503248dcf37f42ca15ceaee13a"
        mlflow.set_tracking_uri("https://dagshub.com/toancodepython/ml-flow.mlflow")
        os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
        os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

        experiment = next((exp for exp in mlflow.search_experiments() if exp.name == experiment_name), None)
        if experiment:
            runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])
            return {row["tags.mlflow.runName"]: row["run_id"] for _, row in runs.iterrows()}
        return {}
    except Exception as e:
        st.warning("Kh√¥ng th·ªÉ l·∫•y danh s√°ch m√¥ h√¨nh t·ª´ MLflow.")
        
        return []

def decision():
    tab1, tab3 = st.tabs(["‚öôÔ∏è Hu·∫•n luy·ªán",  "üî•Mlflow"])

    with tab1:
        display()

    with tab3:
        import mlflow_web
        mlflow_web.display()
decision()